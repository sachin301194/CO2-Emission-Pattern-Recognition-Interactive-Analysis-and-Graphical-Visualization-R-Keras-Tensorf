bank.df[, 1] <- as.factor(bank.df[, 1])
bank.df[, 2] <- as.factor(bank.df[, 2])
bank.df[, 3] <- as.factor(bank.df[, 3])
# Rearranging the column order
bank.df<-bank.df[,c(2,3,1)]
bank.df
# Splitting the data into training and validation sets.
set.seed(301)
train.index <- sample(row.names(bank.df), 0.6*dim(bank.df)[1])
valid.index <- setdiff(row.names(bank.df), train.index)
train.df <- bank.df[train.index, ]
valid.df <- bank.df[valid.index, ]
melted.bank<-melt(bank.df,id=c("Online","CreditCard"),
variable= "Personal.Loan",
value.name= "Count")
library(reshape)
melted.bank<-melt(bank.df,id=c("Online","CreditCard"),
variable= "Personal.Loan",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Online+CreditCard~Personal.Loan)
head(cast.bank,5)
table(train.df$CreditCard, train.df$Online, train.df$Personal.Loan, dnn = c("CreditCard", "Online", "Personal.Loan"))
prob<-(882/5000)
prob
prob<-(882/5000)*100
prob
prob<-(882/5000)
prob
library(reshape)
melted.bank<-melt(bank.df,id=c("CreditCard","Personal.Loan"),
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, CreditCard+Personal.Loan~Online)
head(cast.bank,5)
prob<-(143/5000)
prob
library(reshape)
melted.bank<-melt(bank.df,id=c("Personal.Loan"),
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~Online)
head(cast.bank,5)
library(reshape)
melted.bank<-melt(bank.df,id=c("Personal.Loan"),
variable= "CreditCard",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard)
head(cast.bank,5)
library(reshape)
melted.bank<-melt(bank.df,id=c("Personal.Loan"),
variable= "CreditCard",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard)
head(cast.bank,5)
library(reshape)
melted.bank<-melt(bank.df,id="Personal.Loan",
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~Online)
head(cast.bank,5)
library(reshape)
melted.bank<-melt(bank.df,"Personal.Loan",
variable= "CreditCard",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard)
head(cast.bank,5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, value.var="freq")
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, Count="freq")
library(reshape)
melted.bank<-melt(bank.df,"Personal.Loan",
variable= "CreditCard")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, value.var="freq")
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, sum)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, count)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, count)
library(reshape2)
?dcast
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, count)
library(reshape2)
?dcast
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard, length)
head(cast.bank,5)
bank.df <- read.csv("UniversalBank.csv")
bank.df
bank.df <- bank.df[,c(10,13,14)]
bank.df[, 1] <- as.factor(bank.df[, 1])
bank.df[, 2] <- as.factor(bank.df[, 2])
bank.df[, 3] <- as.factor(bank.df[, 3])
# Rearranging the column order
bank.df<-bank.df[,c(2,3,1)]
bank.df
# Splitting the data into training and validation sets.
set.seed(301)
train.index <- sample(row.names(bank.df), 0.6*dim(bank.df)[1])
valid.index <- setdiff(row.names(bank.df), train.index)
train.df <- bank.df[train.index, ]
valid.df <- bank.df[valid.index, ]
library(reshape)
melted.bank<-melt(bank.df,id="Personal.Loan",
variable= "Online", value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, Personal.Loan~Online)
head(cast.bank,5)
library(reshape)
melted.bank<-melt(bank.df,"Personal.Loan",
variable= "CreditCard")
head(melted.bank, 5)
library(reshape2)
?dcast
cast.bank<-dcast(melted.bank, Personal.Loan~CreditCard)
head(cast.bank,5)
library(reshape)
melted.bank<-melt(bank.df,id=c("CreditCard","Personal.Loan"),
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, CreditCard+Personal.Loan~Online)
head(cast.bank,5)
View(melted.bank)
library(reshape)
melted.bank1<-melt(bank.df,id="Personal.Loan",
variable= "Online", value.name= "Count")
head(melted.bank1, 5)
library(reshape2)
cast.bank<-dcast(melted.bank1, Personal.Loan~Online)
head(cast.bank,5)
View(bank.df)
library(reshape2)
cast.bank1<-dcast(melted.bank1, Personal.Loan~Online)
head(cast.bank1,5)
bank.df <- read.csv("UniversalBank.csv")
bank.df
bank.df <- bank.df[,c(10,13,14)]
bank.df[, 1] <- as.factor(bank.df[, 1])
bank.df[, 2] <- as.factor(bank.df[, 2])
bank.df[, 3] <- as.factor(bank.df[, 3])
# Rearranging the column order
bank.df<-bank.df[,c(2,3,1)]
bank.df
# Splitting the data into training and validation sets.
set.seed(301)
train.index <- sample(row.names(bank.df), 0.6*dim(bank.df)[1])
valid.index <- setdiff(row.names(bank.df), train.index)
train.df <- bank.df[train.index, ]
valid.df <- bank.df[valid.index, ]
library(reshape)
melted.bank<-melt(bank.df,id=c("CreditCard","Personal.Loan"),
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, CreditCard+Personal.Loan~Online)
head(cast.bank,5)
prob<-(143/5000)
prob
library(reshape)
melted.bank1<-melt(bank.df,id="Personal.Loan",
variable= "Online", value.name= "Count")
head(melted.bank1, 5)
library(reshape2)
cast.bank1<-dcast(melted.bank1, Personal.Loan~Online)
head(cast.bank1,5)
library(reshape)
melted.bank1<-melt(bank.df,id=c("Personal.Loan"),
variable= "Online", value.name= "Count")
head(melted.bank1, 5)
library(reshape2)
cast.bank1<-dcast(melted.bank1,Personal.Loan~Online)
head(cast.bank1,5)
library(reshape)
melted.bank2<-melt(bank.df,id="Personal.Loan",
variable= "CreditCard")
head(melted.bank2, 5)
library(reshape2)
?dcast
cast.bank2<-dcast(melted.bank2, Personal.Loan~CreditCard)
head(cast.bank2,5)
pivot_loan_online<-cast.bank1[,c(1,2)]
pivot_loan_online
pivot_loan_cc<-cast.bank1[,c(1,3)]
pivot_loan_cc
library(reshape)
melted.bank<-melt(train.df,id=c("CreditCard","Personal.Loan"),
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, CreditCard+Personal.Loan~Online)
head(cast.bank,5)
prob<-(88/3000)
prob
library(reshape)
melted.bank1<-melt(train.df,id=c("Personal.Loan"),
variable= "Online", value.name= "Count")
head(melted.bank1, 5)
library(reshape2)
cast.bank1<-dcast(melted.bank1,Personal.Loan~Online)
head(cast.bank1,5)
table(train.df$Personal.Loan, train.df$Online, dnn = c("Personal.Loan", "Online"))
table(train.df$Personal.Loan, train.df$CreditCard, dnn = c("Personal.Loan", "CreditCard"))
# Splitting the data into training and validation sets.
set.seed(301)
train.index <- sample(row.names(bank.df), 0.6*dim(bank.df)[1])
valid.index <- setdiff(row.names(bank.df), train.index)
train.df <- bank.df[train.index, ]
valid.df <- bank.df[valid.index, ]
library(reshape)
melted.bank<-melt(train.df,id=c("CreditCard","Personal.Loan"),
variable= "Online",
value.name= "Count")
head(melted.bank, 5)
library(reshape2)
cast.bank<-dcast(melted.bank, CreditCard+Personal.Loan~Online)
head(cast.bank,5)
prob<-(88/3000)
prob
library(reshape)
melted.bank1<-melt(train.df,id=c("Personal.Loan"),
variable= "Online", value.name= "Count")
head(melted.bank1, 5)
library(reshape2)
cast.bank1<-dcast(melted.bank1,Personal.Loan~Online)
head(cast.bank1,5)
pivot_loan_online<-cast.bank1[,c(1,2)]
pivot_loan_online
table(train.df$Personal.Loan, train.df$Online, dnn = c("Personal.Loan", "Online"))
table(train.df$Personal.Loan, train.df$CreditCard, dnn = c("Personal.Loan", "CreditCard"))
library("FNN")
nn <- knn(train = train.norm.df[, -1], test = new.norm.df, cl = train.norm.df[, 1], k = 1)
table(train.df$CreditCard, train.df$Online, train.df$Personal.Loan, dnn = c("CreditCard", "Online", "Personal.Loan"))
prob<-(53/53+482)
prob
prob<-(53/(53+482))
prob
library(reshape)
library(caret)
library(FNN)
bank.df<- read.csv("UniversalBank.csv")
bank.df
bank.df$Education <- as.factor(bank.df$Education)
bank.df[,c("Education_1", "Education_2", "Education_3")] <- model.matrix( ~ 0 + Education, data = bank.df)
bank.df
bank.df_new<-bank.df[,c(-1,-5,-8)]
bank.df_new[,7]<-as.factor(bank.df_new[,7])
bank.df_new
new.df<-data.frame(Age  =  40, Experience  =  10,  Income  =  84,  Family  =  2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities.Account  =  0,  CD.Account  =  0,  Online  =  1, CreditCard  =  1)
bank.df_new<-bank.df_new[,c(7,1,2,3,4,5,12,13,14,6,8,9,10,11)]
summary(bank.df_new)
norm.values <- preProcess(bank.df_new[, -1], method=c("center", "scale"))
norm.values
train.index<-sample(row.names(bank.df_new), 0.6*dim(bank.df_new))
valid.index<-setdiff(row.names(bank.df_new),train.index)
train.df<-bank.df_new[train.index,]
valid.df<-bank.df_new[valid.index,]
train.norm.df <- train.df
test.norm.df <- test.df
train.norm.df <- train.df
valid.norm.df <- valid.df
bank.norm.df <- bank.df_new
train.norm.df[, -1] <- predict(norm.values, train.df[, -1])
valid.norm.df[, -1] <- predict(norm.values, valid.df[, -1])
bank.norm.df[, -1] <- predict(norm.values, bank.df_new[, -1])
new.norm.df <- predict(norm.values, new.df)
library("FNN")
nn <- knn(train = train.norm.df[, -1], test = new.norm.df, cl = train.norm.df[, 1], k = 1)
row.names(train.df)[attr(as.data.frame(nn), "nn.index")]
library("FNN")
nn <- knn(train = train.norm.df[, -1], test = new.norm.df, cl = train.norm.df[, 1], k = 1)
nn
accuracy.df <‐ data.frame(k = seq(1,20, 1), accuracy = rep(0, 20))
accuracy.df
library(e1071)
for(i in 1:20) {
knn.pred <‐ knn(train.norm.df[, -1],valid.norm.df[, -1],cl = train.norm.df[, 1], k = i)
accuracy.df[i, 2] <‐ confusionMatrix(knn.pred, valid.norm.df[, 1])$overall[1]
}
accuracy.df
plot(accuracy.df, type = "b")
nn2 <- knn(train.norm.df[, -1], test.norm.df[, -1], cl = train.norm.df[, 1], k = 5)
nn2 <- knn(train.norm.df[, -1], test.norm.df[, -1], cl = train.norm.df[, 1], k = 5)
nn2 <- knn(train.norm.df[, -1], valid.norm.df[, -1], cl = train.norm.df[, 1], k = 5)
confusionMatrix(nn2, valid.norm.df[, 1])
new.df2<-data.frame(Age  =  40, Experience  =  10,Income  =  84,Family  =  2,CCAvg = 2,Education_1 = 0,Education_2 = 1, Education_3 = 0,Mortgage = 0, Securities.Account  =  0,CD.Account  =  0, Online  =  1,CreditCard  =  1)
new.norm.df2 <- predict(norm.values, new.df2)
nn2 <- knn(train = train.norm.df[, -1], test = new.norm.df2, cl = train.norm.df[, 1], k = 5)
nn2
train.index <- sample(row.names(bank.df_new), 0.5*dim(bank.df_new)[1])
valid.index <- sample(setdiff(row.names(bank.df_new), train.index), 0.3*dim(bank.df_new)[1])
test.index <- setdiff(row.names(bank.df_new), union(train.index, valid.index))
train.df <- bank.df_new[train.index, ]
valid.df <- bank.df_new[valid.index, ]
test.df <- bank.df_new[test.index, ]
train.norm.df <- train.df
valid.norm.df <- valid.df
test.norm.df <- test.df
bank.norm.df <- bank.df_new
norm.values <- preProcess(train.df[, -1], method=c("center", "scale"))
train.norm.df[, -1] <- predict(norm.values, train.df[, -1])
valid.norm.df[, -1] <- predict(norm.values, valid.df[, -1])
test.norm.df[, -1] <- predict(norm.values, test.df[, -1])
bank.norm.df[, -1] <- predict(norm.values, bank.df_new[, -1])
nn_valid <- knn(train.norm.df[, -1], valid.norm.df[, -1], cl = train.norm.df[, 1], k = 5)
confusionMatrix(nn_valid, valid.norm.df[, 1])
nn_test <- knn(train.norm.df[, -1], test.norm.df[, -1], cl = train.norm.df[, 1], k = 5)
confusionMatrix(nn_test, test.norm.df[, 1])
# Splitting the data into training and validation sets.
set.seed(301)
train.index <- sample(row.names(bank.df), 0.6*dim(bank.df)[1])
valid.index <- setdiff(row.names(bank.df), train.index)
train.df <- bank.df[train.index, ]
valid.df <- bank.df[valid.index, ]
table(train.df$CreditCard, train.df$Online, train.df$Personal.Loan, dnn = c("CreditCard", "Online", "Personal.Loan"))
prob<-(53/(53+482))
prob
table(train.df$Personal.Loan, train.df$Online, dnn = c("Personal.Loan", "Online"))
table(train.df$Personal.Loan, train.df$CreditCard, dnn = c("Personal.Loan", "CreditCard"))
prob1<-88/(205+88)
prob1
prob2<-185/(185+108)
prob2
prob2<-293/3000
prob2
prob4<-205/(205+88)
prob4
prob5<-108/(185+108)
prob5
prob6<-2707/3000
prob6
prob1*prob2*prob3 / (prob1*prob2*prob3 + prob4*prob5*prob6)
prob3<-293/3000
prob3
prob1*prob2*prob3 / (prob1*prob2*prob3 + prob4*prob5*prob6)
library(e1071)
# run naive bayes
bank.nb <- naiveBayes(Personal.Loan ~ ., data = train.df)
bank.nb
## predict probabilities
pred.prob <- predict(bank.nb, newdata = train.df, type = "raw")
## predict class membership
pred.class <- predict(bank.nb, newdata = train.df)
df <- data.frame(actual = train.df$Personal.Loan, predicted = pred.class, pred.prob)
library(e1071)
# run naive bayes
bank.nb <- naiveBayes(Personal.Loan ~ ., data = train.df)
bank.nb
## predict probabilities
pred.prob <- predict(bank.nb, newdata = train.df, type = "raw")
## predict class membership
pred.class <- predict(bank.nb, newdata = train.df)
df <- data.frame(actual = train.df$Personal.Loan, predicted = pred.class, pred.prob)
# Splitting the data into training and validation sets.
set.seed(301)
train.index <- sample(row.names(bank.df), 0.6*dim(bank.df)[1])
valid.index <- setdiff(row.names(bank.df), train.index)
train.df <- bank.df[train.index, ]
valid.df <- bank.df[valid.index, ]
df <- data.frame(actual = train.df$Personal.Loan, predicted = pred.class, pred.prob)
shiny::runApp('myApp')
runApp()
install.packages("circlize")
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp()
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
runApp('myApp')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
Model_FNN <- read_csv("C:/USA PC/IE 6600 Project/Model_FNN.csv")
range(Model_FNN)
range(Model_FNN$PersonsPerHousehold)
range(Model_FNN$PersonsPerHousehold)[1]
runApp()
Model_FNN[Model_FNN$PersonsPerHousehold >= range(Model_FNN$PersonsPerHousehold)[1] & Model_FNN$PersonsPerHousehold <= range(Model_FNN$PersonsPerHousehold)[2],] %>% group_by(ZipCode) %>%
arrange(desc('Total Household Carbon Footprint  (tCO2e/yr).y')) %>% head(30)
Model_FNN[Model_FNN$PersonsPerHousehold >= range(Model_FNN$PersonsPerHousehold)[1] & Model_FNN$PersonsPerHousehold <= range(Model_FNN$PersonsPerHousehold)[2],] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(30)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
Model_FNN[Model_FNN$PersonsPerHousehold >= input$range[1] & Model_FNN$PersonsPerHousehold <= input$range[2],] %>% group_by(ZipCode) %>%
arrange(desc('Total Household Carbon Footprint  (tCO2e/yr).y')) %>% head(1000)
Model_FNN[Model_FNN$PersonsPerHousehold >= 1 & Model_FNN$PersonsPerHousehold <= 5,] %>% group_by(ZipCode) %>%
arrange(desc('Total Household Carbon Footprint  (tCO2e/yr).y')) %>% head(1000)
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
Model_LSTM <- read_csv("Model_LSTM.csv")
View(Model_LSTM)
Model_RNN[Model_RNN$PersonsPerHousehold >= 1 & Model_RNN$PersonsPerHousehold <= 1400,] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000)
Model_RNN <- read_csv("Model_RNN.csv")
Model_RNN[Model_RNN$PersonsPerHousehold >= 1 & Model_RNN$PersonsPerHousehold <= 1400,] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000)
View(Model_RNN[Model_RNN$PersonsPerHousehold >= 1 & Model_RNN$PersonsPerHousehold <= 1400,] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000))
runApp()
View(Model_RNN[Model_RNN$PersonsPerHousehold >= 1 & Model_RNN$PersonsPerHousehold <= 1400,] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000))
View(Model_RNN[Model_RNN$PersonsPerHousehold >= 1 & Model_RNN$PersonsPerHousehold <= 1.1,] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000))
range(Model_LSTM$PersonsPerHousehold)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
Model_FNN <- read_csv("Model_FNN.csv")
Model_RNN <- read_csv("Model_RNN.csv")
Model_LSTM <- read_csv("Model_LSTM.csv")
runApp()
runApp()
runApp()
Model_FNN[Model_FNN$PersonsPerHousehold >= input$range1[1] & Model_FNN$PersonsPerHousehold <= input$range1[2],] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000)
Model_FNN[Model_FNN$PersonsPerHousehold >= 1 & Model_FNN$PersonsPerHousehold <= 2,] %>% group_by(ZipCode) %>%
arrange(desc(`Total Household Carbon Footprint (tCO2e/yr).y`)) %>% head(1000)
runApp()
shiny::runApp()
